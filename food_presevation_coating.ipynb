{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1b644001-4b10-4117-915e-ba20d62bf6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "557d6032-954a-4ba9-9a76-5fdbffff172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"food_coating_recommendation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d9559f2-ad95-4f03-8d5d-137d87c460ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Type</th>\n",
       "      <th>Moisture Content (%)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Perishability (1-10)</th>\n",
       "      <th>Coating Type</th>\n",
       "      <th>Barrier Property</th>\n",
       "      <th>Compatibility (1-10)</th>\n",
       "      <th>Shelf Life Without Coating (days)</th>\n",
       "      <th>Shelf Life With Coating (days)</th>\n",
       "      <th>Storage Temp (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Fruit</td>\n",
       "      <td>84</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Firm</td>\n",
       "      <td>7</td>\n",
       "      <td>Carnauba wax</td>\n",
       "      <td>Moisture</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banana</td>\n",
       "      <td>Fruit</td>\n",
       "      <td>74</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Soft</td>\n",
       "      <td>8</td>\n",
       "      <td>Chitosan</td>\n",
       "      <td>Antimicrobial</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strawberry</td>\n",
       "      <td>Fruit</td>\n",
       "      <td>91</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Soft</td>\n",
       "      <td>9</td>\n",
       "      <td>Alginate</td>\n",
       "      <td>Antioxidant</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cucumber</td>\n",
       "      <td>Vegetable</td>\n",
       "      <td>96</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Firm</td>\n",
       "      <td>6</td>\n",
       "      <td>Beeswax</td>\n",
       "      <td>Moisture</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Fruit</td>\n",
       "      <td>94</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Firm</td>\n",
       "      <td>7</td>\n",
       "      <td>Zein</td>\n",
       "      <td>Oxygen</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Food       Type  Moisture Content (%)   pH Texture  \\\n",
       "0       Apple      Fruit                    84  3.3    Firm   \n",
       "1      Banana      Fruit                    74  4.5    Soft   \n",
       "2  Strawberry      Fruit                    91  3.5    Soft   \n",
       "3    Cucumber  Vegetable                    96  5.5    Firm   \n",
       "4      Tomato      Fruit                    94  4.3    Firm   \n",
       "\n",
       "   Perishability (1-10)  Coating Type Barrier Property  Compatibility (1-10)  \\\n",
       "0                     7  Carnauba wax         Moisture                     9   \n",
       "1                     8      Chitosan    Antimicrobial                     7   \n",
       "2                     9      Alginate      Antioxidant                     8   \n",
       "3                     6       Beeswax         Moisture                     8   \n",
       "4                     7          Zein           Oxygen                     7   \n",
       "\n",
       "   Shelf Life Without Coating (days)  Shelf Life With Coating (days)  \\\n",
       "0                                 14                              30   \n",
       "1                                  5                              12   \n",
       "2                                  3                               7   \n",
       "3                                  7                              14   \n",
       "4                                  7                              14   \n",
       "\n",
       "   Storage Temp (°C)  Humidity (%)  \n",
       "0                  4            90  \n",
       "1                 13            85  \n",
       "2                  2            90  \n",
       "3                 10            95  \n",
       "4                 10            85  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33001ea7-55af-4f8a-98c9-54f251c6703f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns found: ['Food', 'Type', 'Texture', 'Coating Type', 'Barrier Property']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns found:\", list(categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb88f092-4f93-48d7-b262-e17b76339fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_features = ['Type', 'Texture', 'Coating Type']\n",
    "numerical_features = ['Moisture Content (%)', 'pH', 'Perishability (1-10)', 'Storage Temp (°C)', 'Humidity (%)']\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "X = preprocessor.fit_transform(df)\n",
    "\n",
    "# Get feature names after encoding\n",
    "feature_names = (numerical_features + \n",
    "                 preprocessor.named_transformers_['cat']\n",
    "                 .get_feature_names_out(categorical_features).tolist())\n",
    "\n",
    "X_transformed = preprocessor.transform(df)\n",
    "feature_names = (numerical_features + \n",
    "                 preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist())\n",
    "df_transformed = pd.DataFrame(X_transformed, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4ebf02b6-e2b4-46d7-b354-aa416a6c9499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Moisture Content (%)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Perishability (1-10)</th>\n",
       "      <th>Storage Temp (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Type_Fruit</th>\n",
       "      <th>Type_Fungus</th>\n",
       "      <th>Type_Grain</th>\n",
       "      <th>Type_Meat</th>\n",
       "      <th>Type_Nut</th>\n",
       "      <th>...</th>\n",
       "      <th>Coating Type_Pullulan</th>\n",
       "      <th>Coating Type_Shellac</th>\n",
       "      <th>Coating Type_Shellac-carnauba</th>\n",
       "      <th>Coating Type_Silica-based</th>\n",
       "      <th>Coating Type_Sodium alginate</th>\n",
       "      <th>Coating Type_Soy protein</th>\n",
       "      <th>Coating Type_Whey protein</th>\n",
       "      <th>Coating Type_Xanthan gum</th>\n",
       "      <th>Coating Type_Zein</th>\n",
       "      <th>Coating Type_Zein-wax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299083</td>\n",
       "      <td>-1.620481</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.281781</td>\n",
       "      <td>-0.703779</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>1.447698</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.705687</td>\n",
       "      <td>-1.467697</td>\n",
       "      <td>1.409271</td>\n",
       "      <td>-0.740781</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996119</td>\n",
       "      <td>0.060138</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879946</td>\n",
       "      <td>-0.856563</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.489062</td>\n",
       "      <td>0.289314</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>3.238271</td>\n",
       "      <td>-3.730911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.430975</td>\n",
       "      <td>-0.245429</td>\n",
       "      <td>-1.138257</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>-1.012263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.165608</td>\n",
       "      <td>0.824056</td>\n",
       "      <td>1.409271</td>\n",
       "      <td>-1.138686</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.630299</td>\n",
       "      <td>0.212922</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.740781</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.531428</td>\n",
       "      <td>0.442097</td>\n",
       "      <td>-1.138257</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.212922</td>\n",
       "      <td>-1.775139</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.938033</td>\n",
       "      <td>0.442097</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.240997</td>\n",
       "      <td>-1.085738</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>1.447698</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.223694</td>\n",
       "      <td>0.594881</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>-0.740781</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.339867</td>\n",
       "      <td>0.900448</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.589515</td>\n",
       "      <td>0.671272</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.862644</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>-1.138686</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.763774</td>\n",
       "      <td>0.594881</td>\n",
       "      <td>1.409271</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.223694</td>\n",
       "      <td>1.740757</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>-1.012263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.763774</td>\n",
       "      <td>-0.245429</td>\n",
       "      <td>-1.138257</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.299083</td>\n",
       "      <td>-1.238522</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.124824</td>\n",
       "      <td>-1.467697</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.740781</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.589515</td>\n",
       "      <td>-1.391305</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.938033</td>\n",
       "      <td>0.824056</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.299083</td>\n",
       "      <td>-1.620481</td>\n",
       "      <td>1.409271</td>\n",
       "      <td>-0.740781</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.473342</td>\n",
       "      <td>-1.467697</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>-1.012263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.763774</td>\n",
       "      <td>0.824056</td>\n",
       "      <td>-1.138257</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.049435</td>\n",
       "      <td>1.358798</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.240997</td>\n",
       "      <td>-1.544089</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.763774</td>\n",
       "      <td>-0.703779</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.165608</td>\n",
       "      <td>1.206015</td>\n",
       "      <td>1.409271</td>\n",
       "      <td>-1.138686</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.281781</td>\n",
       "      <td>0.518489</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.740781</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.531428</td>\n",
       "      <td>0.060138</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>1.447698</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.107522</td>\n",
       "      <td>0.289314</td>\n",
       "      <td>-1.775139</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.705687</td>\n",
       "      <td>0.060138</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.473342</td>\n",
       "      <td>-1.620481</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.066738</td>\n",
       "      <td>1.206015</td>\n",
       "      <td>1.409271</td>\n",
       "      <td>-1.138686</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-4.289738</td>\n",
       "      <td>0.824056</td>\n",
       "      <td>-3.048904</td>\n",
       "      <td>3.238271</td>\n",
       "      <td>-3.730911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.397953</td>\n",
       "      <td>0.365705</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.740781</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.415256</td>\n",
       "      <td>0.671272</td>\n",
       "      <td>-1.138257</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.415256</td>\n",
       "      <td>-1.696872</td>\n",
       "      <td>1.409271</td>\n",
       "      <td>-0.740781</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-2.140544</td>\n",
       "      <td>0.518489</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>-1.012263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.647601</td>\n",
       "      <td>0.442097</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.473342</td>\n",
       "      <td>-1.162130</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.066738</td>\n",
       "      <td>1.053231</td>\n",
       "      <td>1.409271</td>\n",
       "      <td>-1.138686</td>\n",
       "      <td>1.026724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.357169</td>\n",
       "      <td>0.365705</td>\n",
       "      <td>-1.138257</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>0.347062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.281781</td>\n",
       "      <td>1.817149</td>\n",
       "      <td>-0.501375</td>\n",
       "      <td>-0.342876</td>\n",
       "      <td>-1.012263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Moisture Content (%)        pH  Perishability (1-10)  Storage Temp (°C)  \\\n",
       "0               0.299083 -1.620481              0.135507          -0.342876   \n",
       "1              -0.281781 -0.703779              0.772389           1.447698   \n",
       "2               0.705687 -1.467697              1.409271          -0.740781   \n",
       "3               0.996119  0.060138             -0.501375           0.850840   \n",
       "4               0.879946 -0.856563              0.135507           0.850840   \n",
       "5              -2.489062  0.289314             -0.501375           3.238271   \n",
       "6              -2.430975 -0.245429             -1.138257          -0.342876   \n",
       "7              -0.165608  0.824056              1.409271          -1.138686   \n",
       "8              -0.630299  0.212922              0.135507          -0.740781   \n",
       "9               0.531428  0.442097             -1.138257          -0.342876   \n",
       "10              0.008651  0.212922             -1.775139           0.850840   \n",
       "11              0.938033  0.442097              0.772389          -0.342876   \n",
       "12              0.240997 -1.085738             -0.501375           1.447698   \n",
       "13             -0.223694  0.594881              0.772389          -0.740781   \n",
       "14             -0.339867  0.900448              0.135507          -0.342876   \n",
       "15              0.589515  0.671272             -0.501375          -0.342876   \n",
       "16             -0.862644  0.747664              0.772389          -1.138686   \n",
       "17              0.763774  0.594881              1.409271          -0.342876   \n",
       "18             -0.223694  1.740757             -0.501375          -0.342876   \n",
       "19              0.763774 -0.245429             -1.138257           0.850840   \n",
       "20              0.299083 -1.238522             -0.501375          -0.342876   \n",
       "21              0.124824 -1.467697              0.135507          -0.740781   \n",
       "22              0.589515 -1.391305              0.772389          -0.342876   \n",
       "23              0.938033  0.824056             -0.501375           0.850840   \n",
       "24              0.299083 -1.620481              1.409271          -0.740781   \n",
       "25              0.473342 -1.467697             -0.501375           0.850840   \n",
       "26              0.763774  0.824056             -1.138257          -0.342876   \n",
       "27             -0.049435  1.358798              0.135507          -0.342876   \n",
       "28              0.240997 -1.544089              0.772389          -0.342876   \n",
       "29              0.763774 -0.703779             -0.501375           0.850840   \n",
       "30             -0.165608  1.206015              1.409271          -1.138686   \n",
       "31             -0.281781  0.518489              0.135507          -0.740781   \n",
       "32              0.531428  0.060138              0.772389           1.447698   \n",
       "33             -0.107522  0.289314             -1.775139           0.850840   \n",
       "34              0.705687  0.060138              0.772389          -0.342876   \n",
       "35              0.473342 -1.620481              0.135507          -0.342876   \n",
       "36              0.066738  1.206015              1.409271          -1.138686   \n",
       "37             -4.289738  0.824056             -3.048904           3.238271   \n",
       "38             -0.397953  0.365705              0.135507          -0.740781   \n",
       "39              0.415256  0.671272             -1.138257          -0.342876   \n",
       "40              0.415256 -1.696872              1.409271          -0.740781   \n",
       "41             -2.140544  0.518489             -0.501375          -0.342876   \n",
       "42              0.647601  0.442097              0.135507           0.850840   \n",
       "43              0.473342 -1.162130              0.135507          -0.342876   \n",
       "44              0.066738  1.053231              1.409271          -1.138686   \n",
       "45              0.357169  0.365705             -1.138257          -0.342876   \n",
       "46             -0.281781  1.817149             -0.501375          -0.342876   \n",
       "\n",
       "    Humidity (%)  Type_Fruit  Type_Fungus  Type_Grain  Type_Meat  Type_Nut  \\\n",
       "0       0.347062         1.0          0.0         0.0        0.0       0.0   \n",
       "1      -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "2       0.347062         1.0          0.0         0.0        0.0       0.0   \n",
       "3       1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "4      -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "5      -3.730911         0.0          0.0         1.0        0.0       0.0   \n",
       "6      -1.012263         0.0          0.0         0.0        0.0       0.0   \n",
       "7       1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "8       0.347062         0.0          0.0         0.0        1.0       0.0   \n",
       "9       1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "10      0.347062         0.0          0.0         0.0        0.0       0.0   \n",
       "11      1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "12     -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "13      0.347062         0.0          0.0         0.0        1.0       0.0   \n",
       "14     -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "15      1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "16      0.347062         0.0          0.0         0.0        0.0       0.0   \n",
       "17      0.347062         0.0          1.0         0.0        0.0       0.0   \n",
       "18     -1.012263         0.0          0.0         0.0        0.0       0.0   \n",
       "19      0.347062         0.0          0.0         0.0        0.0       0.0   \n",
       "20      0.347062         1.0          0.0         0.0        0.0       0.0   \n",
       "21     -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "22      0.347062         1.0          0.0         0.0        0.0       0.0   \n",
       "23      1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "24     -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "25     -1.012263         1.0          0.0         0.0        0.0       0.0   \n",
       "26      0.347062         0.0          0.0         0.0        0.0       0.0   \n",
       "27     -0.332601         0.0          0.0         0.0        0.0       0.0   \n",
       "28      0.347062         1.0          0.0         0.0        0.0       0.0   \n",
       "29     -0.332601         0.0          0.0         0.0        0.0       0.0   \n",
       "30      1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "31      0.347062         0.0          0.0         0.0        1.0       0.0   \n",
       "32     -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "33      0.347062         0.0          0.0         0.0        0.0       0.0   \n",
       "34      1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "35     -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "36      1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "37     -3.730911         0.0          0.0         0.0        0.0       1.0   \n",
       "38      0.347062         0.0          0.0         0.0        1.0       0.0   \n",
       "39      0.347062         0.0          0.0         0.0        0.0       0.0   \n",
       "40     -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "41     -1.012263         0.0          0.0         0.0        0.0       0.0   \n",
       "42      0.347062         0.0          0.0         0.0        0.0       0.0   \n",
       "43     -0.332601         1.0          0.0         0.0        0.0       0.0   \n",
       "44      1.026724         0.0          0.0         0.0        0.0       0.0   \n",
       "45      0.347062         0.0          0.0         0.0        0.0       0.0   \n",
       "46     -1.012263         0.0          0.0         0.0        0.0       0.0   \n",
       "\n",
       "    ...  Coating Type_Pullulan  Coating Type_Shellac  \\\n",
       "0   ...                    0.0                   0.0   \n",
       "1   ...                    0.0                   0.0   \n",
       "2   ...                    0.0                   0.0   \n",
       "3   ...                    0.0                   0.0   \n",
       "4   ...                    0.0                   0.0   \n",
       "5   ...                    0.0                   0.0   \n",
       "6   ...                    0.0                   0.0   \n",
       "7   ...                    0.0                   0.0   \n",
       "8   ...                    0.0                   0.0   \n",
       "9   ...                    0.0                   0.0   \n",
       "10  ...                    0.0                   0.0   \n",
       "11  ...                    0.0                   0.0   \n",
       "12  ...                    0.0                   0.0   \n",
       "13  ...                    0.0                   0.0   \n",
       "14  ...                    0.0                   0.0   \n",
       "15  ...                    0.0                   0.0   \n",
       "16  ...                    0.0                   0.0   \n",
       "17  ...                    0.0                   0.0   \n",
       "18  ...                    0.0                   0.0   \n",
       "19  ...                    0.0                   0.0   \n",
       "20  ...                    0.0                   1.0   \n",
       "21  ...                    0.0                   0.0   \n",
       "22  ...                    0.0                   0.0   \n",
       "23  ...                    0.0                   0.0   \n",
       "24  ...                    0.0                   0.0   \n",
       "25  ...                    0.0                   0.0   \n",
       "26  ...                    0.0                   0.0   \n",
       "27  ...                    0.0                   0.0   \n",
       "28  ...                    1.0                   0.0   \n",
       "29  ...                    0.0                   0.0   \n",
       "30  ...                    0.0                   0.0   \n",
       "31  ...                    0.0                   0.0   \n",
       "32  ...                    0.0                   0.0   \n",
       "33  ...                    0.0                   0.0   \n",
       "34  ...                    0.0                   0.0   \n",
       "35  ...                    0.0                   0.0   \n",
       "36  ...                    0.0                   0.0   \n",
       "37  ...                    0.0                   0.0   \n",
       "38  ...                    0.0                   0.0   \n",
       "39  ...                    0.0                   0.0   \n",
       "40  ...                    0.0                   0.0   \n",
       "41  ...                    0.0                   0.0   \n",
       "42  ...                    0.0                   0.0   \n",
       "43  ...                    0.0                   0.0   \n",
       "44  ...                    0.0                   0.0   \n",
       "45  ...                    0.0                   0.0   \n",
       "46  ...                    0.0                   0.0   \n",
       "\n",
       "    Coating Type_Shellac-carnauba  Coating Type_Silica-based  \\\n",
       "0                             0.0                        0.0   \n",
       "1                             0.0                        0.0   \n",
       "2                             0.0                        0.0   \n",
       "3                             0.0                        0.0   \n",
       "4                             0.0                        0.0   \n",
       "5                             0.0                        0.0   \n",
       "6                             0.0                        0.0   \n",
       "7                             0.0                        0.0   \n",
       "8                             0.0                        0.0   \n",
       "9                             0.0                        0.0   \n",
       "10                            0.0                        0.0   \n",
       "11                            0.0                        0.0   \n",
       "12                            0.0                        0.0   \n",
       "13                            0.0                        0.0   \n",
       "14                            0.0                        0.0   \n",
       "15                            0.0                        0.0   \n",
       "16                            0.0                        0.0   \n",
       "17                            0.0                        0.0   \n",
       "18                            0.0                        0.0   \n",
       "19                            0.0                        0.0   \n",
       "20                            0.0                        0.0   \n",
       "21                            0.0                        0.0   \n",
       "22                            0.0                        0.0   \n",
       "23                            0.0                        0.0   \n",
       "24                            0.0                        0.0   \n",
       "25                            0.0                        0.0   \n",
       "26                            0.0                        0.0   \n",
       "27                            0.0                        0.0   \n",
       "28                            0.0                        0.0   \n",
       "29                            0.0                        0.0   \n",
       "30                            0.0                        0.0   \n",
       "31                            0.0                        0.0   \n",
       "32                            0.0                        0.0   \n",
       "33                            0.0                        0.0   \n",
       "34                            0.0                        0.0   \n",
       "35                            0.0                        0.0   \n",
       "36                            0.0                        0.0   \n",
       "37                            0.0                        0.0   \n",
       "38                            0.0                        0.0   \n",
       "39                            0.0                        0.0   \n",
       "40                            0.0                        0.0   \n",
       "41                            0.0                        0.0   \n",
       "42                            0.0                        0.0   \n",
       "43                            1.0                        0.0   \n",
       "44                            0.0                        0.0   \n",
       "45                            0.0                        0.0   \n",
       "46                            0.0                        1.0   \n",
       "\n",
       "    Coating Type_Sodium alginate  Coating Type_Soy protein  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "5                            0.0                       0.0   \n",
       "6                            0.0                       0.0   \n",
       "7                            0.0                       0.0   \n",
       "8                            0.0                       0.0   \n",
       "9                            0.0                       0.0   \n",
       "10                           0.0                       0.0   \n",
       "11                           0.0                       0.0   \n",
       "12                           0.0                       0.0   \n",
       "13                           0.0                       0.0   \n",
       "14                           0.0                       0.0   \n",
       "15                           0.0                       0.0   \n",
       "16                           0.0                       0.0   \n",
       "17                           0.0                       0.0   \n",
       "18                           0.0                       0.0   \n",
       "19                           0.0                       0.0   \n",
       "20                           0.0                       0.0   \n",
       "21                           0.0                       0.0   \n",
       "22                           0.0                       0.0   \n",
       "23                           0.0                       0.0   \n",
       "24                           0.0                       0.0   \n",
       "25                           0.0                       0.0   \n",
       "26                           0.0                       0.0   \n",
       "27                           0.0                       1.0   \n",
       "28                           0.0                       0.0   \n",
       "29                           0.0                       0.0   \n",
       "30                           0.0                       0.0   \n",
       "31                           0.0                       0.0   \n",
       "32                           0.0                       0.0   \n",
       "33                           0.0                       0.0   \n",
       "34                           1.0                       0.0   \n",
       "35                           0.0                       0.0   \n",
       "36                           0.0                       0.0   \n",
       "37                           0.0                       0.0   \n",
       "38                           0.0                       0.0   \n",
       "39                           0.0                       0.0   \n",
       "40                           0.0                       0.0   \n",
       "41                           0.0                       0.0   \n",
       "42                           0.0                       0.0   \n",
       "43                           0.0                       0.0   \n",
       "44                           0.0                       0.0   \n",
       "45                           0.0                       0.0   \n",
       "46                           0.0                       0.0   \n",
       "\n",
       "    Coating Type_Whey protein  Coating Type_Xanthan gum  Coating Type_Zein  \\\n",
       "0                         0.0                       0.0                0.0   \n",
       "1                         0.0                       0.0                0.0   \n",
       "2                         0.0                       0.0                0.0   \n",
       "3                         0.0                       0.0                0.0   \n",
       "4                         0.0                       0.0                1.0   \n",
       "5                         0.0                       0.0                0.0   \n",
       "6                         1.0                       0.0                0.0   \n",
       "7                         0.0                       0.0                0.0   \n",
       "8                         0.0                       0.0                0.0   \n",
       "9                         0.0                       0.0                0.0   \n",
       "10                        0.0                       0.0                0.0   \n",
       "11                        0.0                       0.0                0.0   \n",
       "12                        0.0                       0.0                0.0   \n",
       "13                        1.0                       0.0                0.0   \n",
       "14                        0.0                       0.0                0.0   \n",
       "15                        0.0                       0.0                0.0   \n",
       "16                        0.0                       0.0                0.0   \n",
       "17                        0.0                       0.0                0.0   \n",
       "18                        0.0                       0.0                0.0   \n",
       "19                        0.0                       0.0                0.0   \n",
       "20                        0.0                       0.0                0.0   \n",
       "21                        0.0                       0.0                0.0   \n",
       "22                        0.0                       0.0                0.0   \n",
       "23                        0.0                       0.0                0.0   \n",
       "24                        0.0                       0.0                0.0   \n",
       "25                        0.0                       0.0                0.0   \n",
       "26                        0.0                       0.0                0.0   \n",
       "27                        0.0                       0.0                0.0   \n",
       "28                        0.0                       0.0                0.0   \n",
       "29                        0.0                       1.0                0.0   \n",
       "30                        0.0                       0.0                0.0   \n",
       "31                        0.0                       0.0                0.0   \n",
       "32                        0.0                       0.0                0.0   \n",
       "33                        0.0                       0.0                0.0   \n",
       "34                        0.0                       0.0                0.0   \n",
       "35                        0.0                       0.0                0.0   \n",
       "36                        0.0                       0.0                0.0   \n",
       "37                        0.0                       0.0                0.0   \n",
       "38                        0.0                       0.0                0.0   \n",
       "39                        0.0                       0.0                0.0   \n",
       "40                        0.0                       0.0                0.0   \n",
       "41                        0.0                       0.0                0.0   \n",
       "42                        0.0                       0.0                0.0   \n",
       "43                        0.0                       0.0                0.0   \n",
       "44                        0.0                       0.0                0.0   \n",
       "45                        0.0                       0.0                0.0   \n",
       "46                        0.0                       0.0                0.0   \n",
       "\n",
       "    Coating Type_Zein-wax  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "5                     0.0  \n",
       "6                     0.0  \n",
       "7                     0.0  \n",
       "8                     0.0  \n",
       "9                     0.0  \n",
       "10                    0.0  \n",
       "11                    0.0  \n",
       "12                    0.0  \n",
       "13                    0.0  \n",
       "14                    0.0  \n",
       "15                    0.0  \n",
       "16                    0.0  \n",
       "17                    0.0  \n",
       "18                    0.0  \n",
       "19                    0.0  \n",
       "20                    0.0  \n",
       "21                    0.0  \n",
       "22                    0.0  \n",
       "23                    0.0  \n",
       "24                    0.0  \n",
       "25                    0.0  \n",
       "26                    0.0  \n",
       "27                    0.0  \n",
       "28                    0.0  \n",
       "29                    0.0  \n",
       "30                    0.0  \n",
       "31                    0.0  \n",
       "32                    0.0  \n",
       "33                    0.0  \n",
       "34                    0.0  \n",
       "35                    0.0  \n",
       "36                    0.0  \n",
       "37                    1.0  \n",
       "38                    0.0  \n",
       "39                    0.0  \n",
       "40                    0.0  \n",
       "41                    0.0  \n",
       "42                    0.0  \n",
       "43                    0.0  \n",
       "44                    0.0  \n",
       "45                    0.0  \n",
       "46                    0.0  \n",
       "\n",
       "[47 rows x 50 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2f8f647-ff52-4d70-9923-e7a62b55bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.to_csv('transformed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5e064d4-de8e-44c1-b74b-64782985bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Food', 'Type', 'Moisture Content (%)', 'pH', 'Texture',\n",
      "       'Perishability (1-10)', 'Coating Type', 'Barrier Property',\n",
      "       'Compatibility (1-10)', 'Shelf Life Without Coating (days)',\n",
      "       'Shelf Life With Coating (days)', 'Storage Temp (°C)', 'Humidity (%)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7251b983-107d-477c-83d1-f75dd197b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_transformed.iloc[:, :19]  # Assuming first 19 columns are features\n",
    "targets = df_transformed.iloc[:, 19:]   # Assuming remaining columns are coating types\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f3763ec9-0051-48bb-975b-6efcd73773ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(19,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(targets.shape[1], activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b882f055-bc18-484f-a450-dc5c7fa16008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return 0.001 * (0.1 ** int(epoch / 10))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.005), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8734a70a-a1e6-4c1d-a469-b9d5822a585e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7241 - loss: 0.0382 - val_accuracy: 0.0000e+00 - val_loss: 0.3082\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6207 - loss: 0.0454 - val_accuracy: 0.0000e+00 - val_loss: 0.3098\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7241 - loss: 0.0384 - val_accuracy: 0.0000e+00 - val_loss: 0.3120\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5862 - loss: 0.0451 - val_accuracy: 0.0000e+00 - val_loss: 0.3148\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5862 - loss: 0.0434 - val_accuracy: 0.0000e+00 - val_loss: 0.3171\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7241 - loss: 0.0339 - val_accuracy: 0.0000e+00 - val_loss: 0.3196\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6897 - loss: 0.0418 - val_accuracy: 0.0000e+00 - val_loss: 0.3220\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7586 - loss: 0.0368 - val_accuracy: 0.0000e+00 - val_loss: 0.3245\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5862 - loss: 0.0481 - val_accuracy: 0.0000e+00 - val_loss: 0.3265\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7586 - loss: 0.0350 - val_accuracy: 0.0000e+00 - val_loss: 0.3285\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6207 - loss: 0.0435 - val_accuracy: 0.0000e+00 - val_loss: 0.3285\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6897 - loss: 0.0369 - val_accuracy: 0.0000e+00 - val_loss: 0.3281\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5517 - loss: 0.0390 - val_accuracy: 0.0000e+00 - val_loss: 0.3279\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5862 - loss: 0.0351 - val_accuracy: 0.0000e+00 - val_loss: 0.3284\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5862 - loss: 0.0398 - val_accuracy: 0.0000e+00 - val_loss: 0.3286\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6897 - loss: 0.0378 - val_accuracy: 0.0000e+00 - val_loss: 0.3293\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6897 - loss: 0.0365 - val_accuracy: 0.0000e+00 - val_loss: 0.3302\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.6552 - loss: 0.0375 - val_accuracy: 0.0000e+00 - val_loss: 0.3312\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5862 - loss: 0.0414 - val_accuracy: 0.0000e+00 - val_loss: 0.3321\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7241 - loss: 0.0381 - val_accuracy: 0.0000e+00 - val_loss: 0.3329\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7586 - loss: 0.0339 - val_accuracy: 0.0000e+00 - val_loss: 0.3344\n",
      "Epoch 22/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6207 - loss: 0.0427 - val_accuracy: 0.0000e+00 - val_loss: 0.3362\n",
      "Epoch 23/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7931 - loss: 0.0308 - val_accuracy: 0.0000e+00 - val_loss: 0.3383\n",
      "Epoch 24/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6897 - loss: 0.0368 - val_accuracy: 0.0000e+00 - val_loss: 0.3402\n",
      "Epoch 25/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6552 - loss: 0.0435 - val_accuracy: 0.0000e+00 - val_loss: 0.3412\n",
      "Epoch 26/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6552 - loss: 0.0358 - val_accuracy: 0.0000e+00 - val_loss: 0.3423\n",
      "Epoch 27/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6207 - loss: 0.0457 - val_accuracy: 0.0000e+00 - val_loss: 0.3435\n",
      "Epoch 28/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6207 - loss: 0.0415 - val_accuracy: 0.0000e+00 - val_loss: 0.3438\n",
      "Epoch 29/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7586 - loss: 0.0369 - val_accuracy: 0.0000e+00 - val_loss: 0.3431\n",
      "Epoch 30/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6552 - loss: 0.0472 - val_accuracy: 0.0000e+00 - val_loss: 0.3425\n",
      "Epoch 31/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6897 - loss: 0.0349 - val_accuracy: 0.1250 - val_loss: 0.3428\n",
      "Epoch 32/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7931 - loss: 0.0329 - val_accuracy: 0.0000e+00 - val_loss: 0.3430\n",
      "Epoch 33/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6207 - loss: 0.0429 - val_accuracy: 0.0000e+00 - val_loss: 0.3434\n",
      "Epoch 34/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7586 - loss: 0.0333 - val_accuracy: 0.0000e+00 - val_loss: 0.3437\n",
      "Epoch 35/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8276 - loss: 0.0265 - val_accuracy: 0.0000e+00 - val_loss: 0.3443\n",
      "Epoch 36/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7586 - loss: 0.0307 - val_accuracy: 0.0000e+00 - val_loss: 0.3451\n",
      "Epoch 37/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6897 - loss: 0.0301 - val_accuracy: 0.0000e+00 - val_loss: 0.3463\n",
      "Epoch 38/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6207 - loss: 0.0382 - val_accuracy: 0.0000e+00 - val_loss: 0.3469\n",
      "Epoch 39/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7241 - loss: 0.0356 - val_accuracy: 0.0000e+00 - val_loss: 0.3473\n",
      "Epoch 40/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7241 - loss: 0.0376 - val_accuracy: 0.0000e+00 - val_loss: 0.3478\n",
      "Epoch 41/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6552 - loss: 0.0394 - val_accuracy: 0.0000e+00 - val_loss: 0.3484\n",
      "Epoch 42/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7241 - loss: 0.0257 - val_accuracy: 0.0000e+00 - val_loss: 0.3493\n",
      "Epoch 43/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6552 - loss: 0.0368 - val_accuracy: 0.0000e+00 - val_loss: 0.3509\n",
      "Epoch 44/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6207 - loss: 0.0344 - val_accuracy: 0.0000e+00 - val_loss: 0.3531\n",
      "Epoch 45/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6552 - loss: 0.0322 - val_accuracy: 0.0000e+00 - val_loss: 0.3547\n",
      "Epoch 46/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5172 - loss: 0.0415 - val_accuracy: 0.0000e+00 - val_loss: 0.3556\n",
      "Epoch 47/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6207 - loss: 0.0405 - val_accuracy: 0.0000e+00 - val_loss: 0.3551\n",
      "Epoch 48/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6207 - loss: 0.0350 - val_accuracy: 0.0000e+00 - val_loss: 0.3540\n",
      "Epoch 49/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7241 - loss: 0.0388 - val_accuracy: 0.0000e+00 - val_loss: 0.3530\n",
      "Epoch 50/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6552 - loss: 0.0324 - val_accuracy: 0.0000e+00 - val_loss: 0.3529\n",
      "Epoch 51/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6552 - loss: 0.0315 - val_accuracy: 0.0000e+00 - val_loss: 0.3525\n",
      "Epoch 52/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5517 - loss: 0.0358 - val_accuracy: 0.0000e+00 - val_loss: 0.3517\n",
      "Epoch 53/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7586 - loss: 0.0268 - val_accuracy: 0.0000e+00 - val_loss: 0.3515\n",
      "Epoch 54/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5862 - loss: 0.0389 - val_accuracy: 0.0000e+00 - val_loss: 0.3508\n",
      "Epoch 55/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6897 - loss: 0.0381 - val_accuracy: 0.0000e+00 - val_loss: 0.3489\n",
      "Epoch 56/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7241 - loss: 0.0284 - val_accuracy: 0.0000e+00 - val_loss: 0.3474\n",
      "Epoch 57/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7931 - loss: 0.0355 - val_accuracy: 0.0000e+00 - val_loss: 0.3459\n",
      "Epoch 58/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6897 - loss: 0.0346 - val_accuracy: 0.0000e+00 - val_loss: 0.3455\n",
      "Epoch 59/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7241 - loss: 0.0300 - val_accuracy: 0.0000e+00 - val_loss: 0.3461\n",
      "Epoch 60/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5862 - loss: 0.0349 - val_accuracy: 0.0000e+00 - val_loss: 0.3478\n",
      "Epoch 61/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7241 - loss: 0.0320 - val_accuracy: 0.0000e+00 - val_loss: 0.3508\n",
      "Epoch 62/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6897 - loss: 0.0307 - val_accuracy: 0.0000e+00 - val_loss: 0.3551\n",
      "Epoch 63/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6207 - loss: 0.0335 - val_accuracy: 0.0000e+00 - val_loss: 0.3579\n",
      "Epoch 64/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6207 - loss: 0.0397 - val_accuracy: 0.0000e+00 - val_loss: 0.3601\n",
      "Epoch 65/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6897 - loss: 0.0283 - val_accuracy: 0.0000e+00 - val_loss: 0.3610\n",
      "Epoch 66/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6897 - loss: 0.0325 - val_accuracy: 0.0000e+00 - val_loss: 0.3624\n",
      "Epoch 67/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6552 - loss: 0.0307 - val_accuracy: 0.0000e+00 - val_loss: 0.3634\n",
      "Epoch 68/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7931 - loss: 0.0329 - val_accuracy: 0.0000e+00 - val_loss: 0.3636\n",
      "Epoch 69/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6552 - loss: 0.0338 - val_accuracy: 0.0000e+00 - val_loss: 0.3636\n",
      "Epoch 70/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6897 - loss: 0.0306 - val_accuracy: 0.0000e+00 - val_loss: 0.3634\n",
      "Epoch 71/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6897 - loss: 0.0301 - val_accuracy: 0.0000e+00 - val_loss: 0.3629\n",
      "Epoch 72/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6207 - loss: 0.0298 - val_accuracy: 0.0000e+00 - val_loss: 0.3629\n",
      "Epoch 73/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6897 - loss: 0.0389 - val_accuracy: 0.0000e+00 - val_loss: 0.3622\n",
      "Epoch 74/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.6897 - loss: 0.0329 - val_accuracy: 0.0000e+00 - val_loss: 0.3619\n",
      "Epoch 75/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5862 - loss: 0.0342 - val_accuracy: 0.0000e+00 - val_loss: 0.3621\n",
      "Epoch 76/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6897 - loss: 0.0302 - val_accuracy: 0.0000e+00 - val_loss: 0.3643\n",
      "Epoch 77/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7241 - loss: 0.0299 - val_accuracy: 0.0000e+00 - val_loss: 0.3661\n",
      "Epoch 78/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7241 - loss: 0.0307 - val_accuracy: 0.0000e+00 - val_loss: 0.3668\n",
      "Epoch 79/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7241 - loss: 0.0281 - val_accuracy: 0.0000e+00 - val_loss: 0.3675\n",
      "Epoch 80/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6207 - loss: 0.0373 - val_accuracy: 0.0000e+00 - val_loss: 0.3679\n",
      "Epoch 81/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7586 - loss: 0.0275 - val_accuracy: 0.0000e+00 - val_loss: 0.3685\n",
      "Epoch 82/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7241 - loss: 0.0304 - val_accuracy: 0.0000e+00 - val_loss: 0.3686\n",
      "Epoch 83/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6897 - loss: 0.0342 - val_accuracy: 0.0000e+00 - val_loss: 0.3681\n",
      "Epoch 84/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7241 - loss: 0.0338 - val_accuracy: 0.0000e+00 - val_loss: 0.3678\n",
      "Epoch 85/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8276 - loss: 0.0238 - val_accuracy: 0.0000e+00 - val_loss: 0.3683\n",
      "Epoch 86/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7241 - loss: 0.0312 - val_accuracy: 0.0000e+00 - val_loss: 0.3683\n",
      "Epoch 87/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7931 - loss: 0.0288 - val_accuracy: 0.0000e+00 - val_loss: 0.3682\n",
      "Epoch 88/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6897 - loss: 0.0277 - val_accuracy: 0.0000e+00 - val_loss: 0.3697\n",
      "Epoch 89/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8276 - loss: 0.0231 - val_accuracy: 0.0000e+00 - val_loss: 0.3714\n",
      "Epoch 90/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7241 - loss: 0.0218 - val_accuracy: 0.0000e+00 - val_loss: 0.3729\n",
      "Epoch 91/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7241 - loss: 0.0261 - val_accuracy: 0.0000e+00 - val_loss: 0.3750\n",
      "Epoch 92/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7586 - loss: 0.0283 - val_accuracy: 0.0000e+00 - val_loss: 0.3775\n",
      "Epoch 93/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7586 - loss: 0.0239 - val_accuracy: 0.0000e+00 - val_loss: 0.3803\n",
      "Epoch 94/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7241 - loss: 0.0257 - val_accuracy: 0.0000e+00 - val_loss: 0.3828\n",
      "Epoch 95/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6552 - loss: 0.0305 - val_accuracy: 0.0000e+00 - val_loss: 0.3847\n",
      "Epoch 96/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6897 - loss: 0.0265 - val_accuracy: 0.0000e+00 - val_loss: 0.3859\n",
      "Epoch 97/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7931 - loss: 0.0298 - val_accuracy: 0.0000e+00 - val_loss: 0.3855\n",
      "Epoch 98/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7931 - loss: 0.0248 - val_accuracy: 0.0000e+00 - val_loss: 0.3840\n",
      "Epoch 99/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7241 - loss: 0.0341 - val_accuracy: 0.0000e+00 - val_loss: 0.3846\n",
      "Epoch 100/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6897 - loss: 0.0319 - val_accuracy: 0.0000e+00 - val_loss: 0.3860\n",
      "Epoch 101/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7241 - loss: 0.0311 - val_accuracy: 0.0000e+00 - val_loss: 0.3867\n",
      "Epoch 102/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6897 - loss: 0.0297 - val_accuracy: 0.0000e+00 - val_loss: 0.3876\n",
      "Epoch 103/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6897 - loss: 0.0288 - val_accuracy: 0.0000e+00 - val_loss: 0.3882\n",
      "Epoch 104/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6552 - loss: 0.0276 - val_accuracy: 0.0000e+00 - val_loss: 0.3884\n",
      "Epoch 105/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6897 - loss: 0.0366 - val_accuracy: 0.0000e+00 - val_loss: 0.3877\n",
      "Epoch 106/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7931 - loss: 0.0205 - val_accuracy: 0.0000e+00 - val_loss: 0.3872\n",
      "Epoch 107/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7241 - loss: 0.0212 - val_accuracy: 0.0000e+00 - val_loss: 0.3876\n",
      "Epoch 108/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7931 - loss: 0.0221 - val_accuracy: 0.0000e+00 - val_loss: 0.3884\n",
      "Epoch 109/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7931 - loss: 0.0208 - val_accuracy: 0.0000e+00 - val_loss: 0.3889\n",
      "Epoch 110/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6897 - loss: 0.0352 - val_accuracy: 0.0000e+00 - val_loss: 0.3894\n",
      "Epoch 111/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7586 - loss: 0.0331 - val_accuracy: 0.0000e+00 - val_loss: 0.3898\n",
      "Epoch 112/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7241 - loss: 0.0302 - val_accuracy: 0.0000e+00 - val_loss: 0.3907\n",
      "Epoch 113/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7241 - loss: 0.0265 - val_accuracy: 0.0000e+00 - val_loss: 0.3916\n",
      "Epoch 114/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7241 - loss: 0.0248 - val_accuracy: 0.0000e+00 - val_loss: 0.3920\n",
      "Epoch 115/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7931 - loss: 0.0291 - val_accuracy: 0.0000e+00 - val_loss: 0.3916\n",
      "Epoch 116/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6897 - loss: 0.0282 - val_accuracy: 0.0000e+00 - val_loss: 0.3923\n",
      "Epoch 117/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7586 - loss: 0.0246 - val_accuracy: 0.0000e+00 - val_loss: 0.3926\n",
      "Epoch 118/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6897 - loss: 0.0349 - val_accuracy: 0.0000e+00 - val_loss: 0.3916\n",
      "Epoch 119/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7586 - loss: 0.0256 - val_accuracy: 0.0000e+00 - val_loss: 0.3908\n",
      "Epoch 120/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7931 - loss: 0.0200 - val_accuracy: 0.0000e+00 - val_loss: 0.3898\n",
      "Epoch 121/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6897 - loss: 0.0329 - val_accuracy: 0.0000e+00 - val_loss: 0.3889\n",
      "Epoch 122/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6897 - loss: 0.0371 - val_accuracy: 0.0000e+00 - val_loss: 0.3891\n",
      "Epoch 123/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7931 - loss: 0.0244 - val_accuracy: 0.0000e+00 - val_loss: 0.3900\n",
      "Epoch 124/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7586 - loss: 0.0276 - val_accuracy: 0.0000e+00 - val_loss: 0.3916\n",
      "Epoch 125/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7241 - loss: 0.0231 - val_accuracy: 0.0000e+00 - val_loss: 0.3938\n",
      "Epoch 126/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7586 - loss: 0.0253 - val_accuracy: 0.0000e+00 - val_loss: 0.3969\n",
      "Epoch 127/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7241 - loss: 0.0272 - val_accuracy: 0.0000e+00 - val_loss: 0.4004\n",
      "Epoch 128/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7241 - loss: 0.0234 - val_accuracy: 0.0000e+00 - val_loss: 0.4038\n",
      "Epoch 129/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7931 - loss: 0.0210 - val_accuracy: 0.0000e+00 - val_loss: 0.4065\n",
      "Epoch 130/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6897 - loss: 0.0369 - val_accuracy: 0.0000e+00 - val_loss: 0.4094\n",
      "Epoch 131/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7241 - loss: 0.0328 - val_accuracy: 0.0000e+00 - val_loss: 0.4131\n",
      "Epoch 132/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7586 - loss: 0.0218 - val_accuracy: 0.0000e+00 - val_loss: 0.4143\n",
      "Epoch 133/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7931 - loss: 0.0240 - val_accuracy: 0.0000e+00 - val_loss: 0.4152\n",
      "Epoch 134/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7241 - loss: 0.0334 - val_accuracy: 0.0000e+00 - val_loss: 0.4134\n",
      "Epoch 135/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7241 - loss: 0.0318 - val_accuracy: 0.0000e+00 - val_loss: 0.4111\n",
      "Epoch 136/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7586 - loss: 0.0258 - val_accuracy: 0.0000e+00 - val_loss: 0.4098\n",
      "Epoch 137/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7931 - loss: 0.0228 - val_accuracy: 0.0000e+00 - val_loss: 0.4099\n",
      "Epoch 138/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7241 - loss: 0.0267 - val_accuracy: 0.0000e+00 - val_loss: 0.4115\n",
      "Epoch 139/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7931 - loss: 0.0178 - val_accuracy: 0.0000e+00 - val_loss: 0.4127\n",
      "Epoch 140/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8276 - loss: 0.0165 - val_accuracy: 0.0000e+00 - val_loss: 0.4144\n",
      "Epoch 141/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6552 - loss: 0.0316 - val_accuracy: 0.0000e+00 - val_loss: 0.4166\n",
      "Epoch 142/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7586 - loss: 0.0215 - val_accuracy: 0.0000e+00 - val_loss: 0.4203\n",
      "Epoch 143/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6897 - loss: 0.0265 - val_accuracy: 0.0000e+00 - val_loss: 0.4246\n",
      "Epoch 144/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7931 - loss: 0.0217 - val_accuracy: 0.0000e+00 - val_loss: 0.4291\n",
      "Epoch 145/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7241 - loss: 0.0297 - val_accuracy: 0.0000e+00 - val_loss: 0.4314\n",
      "Epoch 146/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7931 - loss: 0.0199 - val_accuracy: 0.0000e+00 - val_loss: 0.4331\n",
      "Epoch 147/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7586 - loss: 0.0222 - val_accuracy: 0.0000e+00 - val_loss: 0.4347\n",
      "Epoch 148/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7931 - loss: 0.0197 - val_accuracy: 0.0000e+00 - val_loss: 0.4357\n",
      "Epoch 149/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7931 - loss: 0.0217 - val_accuracy: 0.0000e+00 - val_loss: 0.4362\n",
      "Epoch 150/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8276 - loss: 0.0181 - val_accuracy: 0.0000e+00 - val_loss: 0.4374\n",
      "Epoch 151/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8276 - loss: 0.0187 - val_accuracy: 0.0000e+00 - val_loss: 0.4390\n",
      "Epoch 152/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8621 - loss: 0.0212 - val_accuracy: 0.0000e+00 - val_loss: 0.4407\n",
      "Epoch 153/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7241 - loss: 0.0201 - val_accuracy: 0.0000e+00 - val_loss: 0.4408\n",
      "Epoch 154/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7586 - loss: 0.0282 - val_accuracy: 0.0000e+00 - val_loss: 0.4408\n",
      "Epoch 155/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8276 - loss: 0.0228 - val_accuracy: 0.0000e+00 - val_loss: 0.4396\n",
      "Epoch 156/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8276 - loss: 0.0181 - val_accuracy: 0.0000e+00 - val_loss: 0.4396\n",
      "Epoch 157/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7586 - loss: 0.0220 - val_accuracy: 0.0000e+00 - val_loss: 0.4392\n",
      "Epoch 158/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7241 - loss: 0.0289 - val_accuracy: 0.0000e+00 - val_loss: 0.4392\n",
      "Epoch 159/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7931 - loss: 0.0169 - val_accuracy: 0.0000e+00 - val_loss: 0.4390\n",
      "Epoch 160/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6897 - loss: 0.0229 - val_accuracy: 0.0000e+00 - val_loss: 0.4387\n",
      "Epoch 161/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7241 - loss: 0.0283 - val_accuracy: 0.0000e+00 - val_loss: 0.4382\n",
      "Epoch 162/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7931 - loss: 0.0216 - val_accuracy: 0.0000e+00 - val_loss: 0.4397\n",
      "Epoch 163/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6897 - loss: 0.0262 - val_accuracy: 0.0000e+00 - val_loss: 0.4417\n",
      "Epoch 164/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7586 - loss: 0.0245 - val_accuracy: 0.0000e+00 - val_loss: 0.4419\n",
      "Epoch 165/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8276 - loss: 0.0191 - val_accuracy: 0.0000e+00 - val_loss: 0.4426\n",
      "Epoch 166/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7241 - loss: 0.0274 - val_accuracy: 0.0000e+00 - val_loss: 0.4425\n",
      "Epoch 167/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7241 - loss: 0.0213 - val_accuracy: 0.0000e+00 - val_loss: 0.4418\n",
      "Epoch 168/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8621 - loss: 0.0159 - val_accuracy: 0.0000e+00 - val_loss: 0.4407\n",
      "Epoch 169/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7241 - loss: 0.0232 - val_accuracy: 0.0000e+00 - val_loss: 0.4389\n",
      "Epoch 170/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8276 - loss: 0.0207 - val_accuracy: 0.0000e+00 - val_loss: 0.4378\n",
      "Epoch 171/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8276 - loss: 0.0160 - val_accuracy: 0.0000e+00 - val_loss: 0.4382\n",
      "Epoch 172/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8276 - loss: 0.0248 - val_accuracy: 0.0000e+00 - val_loss: 0.4375\n",
      "Epoch 173/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7931 - loss: 0.0209 - val_accuracy: 0.0000e+00 - val_loss: 0.4366\n",
      "Epoch 174/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7931 - loss: 0.0225 - val_accuracy: 0.0000e+00 - val_loss: 0.4354\n",
      "Epoch 175/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8276 - loss: 0.0234 - val_accuracy: 0.0000e+00 - val_loss: 0.4341\n",
      "Epoch 176/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6552 - loss: 0.0231 - val_accuracy: 0.0000e+00 - val_loss: 0.4336\n",
      "Epoch 177/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8276 - loss: 0.0191 - val_accuracy: 0.0000e+00 - val_loss: 0.4341\n",
      "Epoch 178/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7586 - loss: 0.0302 - val_accuracy: 0.0000e+00 - val_loss: 0.4335\n",
      "Epoch 179/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7241 - loss: 0.0214 - val_accuracy: 0.0000e+00 - val_loss: 0.4318\n",
      "Epoch 180/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7241 - loss: 0.0200 - val_accuracy: 0.0000e+00 - val_loss: 0.4327\n",
      "Epoch 181/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6552 - loss: 0.0261 - val_accuracy: 0.0000e+00 - val_loss: 0.4339\n",
      "Epoch 182/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7931 - loss: 0.0262 - val_accuracy: 0.0000e+00 - val_loss: 0.4361\n",
      "Epoch 183/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7931 - loss: 0.0191 - val_accuracy: 0.0000e+00 - val_loss: 0.4384\n",
      "Epoch 184/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7586 - loss: 0.0192 - val_accuracy: 0.0000e+00 - val_loss: 0.4409\n",
      "Epoch 185/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7586 - loss: 0.0201 - val_accuracy: 0.0000e+00 - val_loss: 0.4445\n",
      "Epoch 186/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6897 - loss: 0.0294 - val_accuracy: 0.0000e+00 - val_loss: 0.4467\n",
      "Epoch 187/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7931 - loss: 0.0246 - val_accuracy: 0.0000e+00 - val_loss: 0.4492\n",
      "Epoch 188/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7586 - loss: 0.0228 - val_accuracy: 0.0000e+00 - val_loss: 0.4520\n",
      "Epoch 189/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6897 - loss: 0.0232 - val_accuracy: 0.0000e+00 - val_loss: 0.4542\n",
      "Epoch 190/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8276 - loss: 0.0234 - val_accuracy: 0.0000e+00 - val_loss: 0.4569\n",
      "Epoch 191/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7586 - loss: 0.0231 - val_accuracy: 0.0000e+00 - val_loss: 0.4585\n",
      "Epoch 192/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7241 - loss: 0.0250 - val_accuracy: 0.0000e+00 - val_loss: 0.4607\n",
      "Epoch 193/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7931 - loss: 0.0181 - val_accuracy: 0.0000e+00 - val_loss: 0.4631\n",
      "Epoch 194/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7931 - loss: 0.0143 - val_accuracy: 0.0000e+00 - val_loss: 0.4663\n",
      "Epoch 195/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8966 - loss: 0.0171 - val_accuracy: 0.0000e+00 - val_loss: 0.4688\n",
      "Epoch 196/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7931 - loss: 0.0187 - val_accuracy: 0.0000e+00 - val_loss: 0.4705\n",
      "Epoch 197/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7931 - loss: 0.0258 - val_accuracy: 0.0000e+00 - val_loss: 0.4714\n",
      "Epoch 198/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7931 - loss: 0.0170 - val_accuracy: 0.0000e+00 - val_loss: 0.4724\n",
      "Epoch 199/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8621 - loss: 0.0141 - val_accuracy: 0.0000e+00 - val_loss: 0.4731\n",
      "Epoch 200/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7586 - loss: 0.0261 - val_accuracy: 0.0000e+00 - val_loss: 0.4740\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs = 200, batch_size=64, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "203559cd-5a1c-4d75-87ef-0f5f6848b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7931 - loss: 0.0177 - val_accuracy: 0.0000e+00 - val_loss: 0.4764\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7931 - loss: 0.0253 - val_accuracy: 0.0000e+00 - val_loss: 0.4795\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7586 - loss: 0.0183 - val_accuracy: 0.0000e+00 - val_loss: 0.4825\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8621 - loss: 0.0109 - val_accuracy: 0.0000e+00 - val_loss: 0.4852\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8621 - loss: 0.0159 - val_accuracy: 0.0000e+00 - val_loss: 0.4878\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6897 - loss: 0.0259 - val_accuracy: 0.0000e+00 - val_loss: 0.4894\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7586 - loss: 0.0152 - val_accuracy: 0.0000e+00 - val_loss: 0.4906\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7241 - loss: 0.0262 - val_accuracy: 0.0000e+00 - val_loss: 0.4918\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7241 - loss: 0.0210 - val_accuracy: 0.0000e+00 - val_loss: 0.4920\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7241 - loss: 0.0429 - val_accuracy: 0.0000e+00 - val_loss: 0.4916\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7241 - loss: 0.0195 - val_accuracy: 0.0000e+00 - val_loss: 0.4905\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "27fae938-3935-4d20-a17f-5db18a6ff9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1000 - loss: 0.3664\n",
      "Test accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b03bad69-41e3-469f-b0f9-18088a7a1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_coating(input_data):\n",
    "    # Scale the input data\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(input_scaled)\n",
    "    \n",
    "    # Get the top 3 recommended coatings\n",
    "    top_3_indices = np.argsort(predictions[0])[-3:][::-1]\n",
    "    top_3_coatings = targets.columns[top_3_indices]\n",
    "    \n",
    "    return top_3_coatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0442a4f2-4f4d-4573-a271-384af4e22094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Top 3 recommended coatings:\n",
      "1. Coating Type_Carnauba wax\n",
      "2. Coating Type_Hydroxypropyl methylcellulose\n",
      "3. Coating Type_Beeswax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sample_input = np.array([[0.29908, -1.62048, 0.13551, -0.34288, 0.34706, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
    "recommendations = recommend_coating(sample_input)\n",
    "print(\"Top 3 recommended coatings:\")\n",
    "for i, coating in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {coating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d554befe-284e-4de4-8308-4bd4d64ac353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample input 1:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Top 3 recommended coatings:\n",
      "1. Coating Type_Carnauba wax\n",
      "2. Coating Type_Hydroxypropyl methylcellulose\n",
      "3. Coating Type_Beeswax\n",
      "\n",
      "Sample input 2:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Top 3 recommended coatings:\n",
      "1. Coating Type_Carnauba wax\n",
      "2. Coating Type_Whey protein\n",
      "3. Coating Type_Hydroxypropyl methylcellulose\n",
      "\n",
      "Sample input 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Top 3 recommended coatings:\n",
      "1. Coating Type_Whey protein\n",
      "2. Coating Type_Cellulose\n",
      "3. Coating Type_Carnauba wax\n",
      "\n",
      "Sample input 4:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Top 3 recommended coatings:\n",
      "1. Coating Type_Carnauba wax\n",
      "2. Coating Type_Nanocellulose\n",
      "3. Coating Type_Hydroxypropyl methylcellulose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample input 2: Different continuous variables, different categorical flags\n",
    "sample_input_2 = np.array([[0.5, -0.8, 0.2, 0.1, 0.6, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "# Sample input 3: Negative values for continuous variables, multiple categorical flags\n",
    "sample_input_3 = np.array([[-0.1, -1.2, -0.5, -0.7, -0.3, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]])\n",
    "\n",
    "# Sample input 4: Extreme values for continuous variables\n",
    "sample_input_4 = np.array([[2.0, -3.0, 1.5, -2.5, 1.8, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
    "\n",
    "# Test these inputs\n",
    "for i, sample in enumerate([sample_input, sample_input_2, sample_input_3, sample_input_4], 1):\n",
    "    print(f\"\\nSample input {i}:\")\n",
    "    recommendations = recommend_coating(sample)\n",
    "    print(\"Top 3 recommended coatings:\")\n",
    "    for j, coating in enumerate(recommendations, 1):\n",
    "        print(f\"{j}. {coating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4cd54-a2cb-4502-926a-d464eb8d0104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
